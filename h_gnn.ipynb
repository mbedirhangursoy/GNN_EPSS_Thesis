{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import json\n",
    "from data_related.get_epss_score import get_epss_scores\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  label={ x=[2, 2] },\n",
      "  attribute={ x=[7, 32] },\n",
      "  (label, to, attribute)={\n",
      "    edge_index=[2, 14],\n",
      "    edge_attr=[14, 2],\n",
      "  },\n",
      "  (attribute, rev_to, label)={ edge_index=[2, 14] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open('data_related/h_gnn_output.json') as data_values:\n",
    "    data_values = json.load(data_values)\n",
    "    \n",
    "    data_values = {'CVE-2025-2324': {'basescore': 5.9, 'baseseverity': 2, 'confidentialityimpact': 3, 'integrityimpact': 1, 'vendor': 'Progress', 'description': ['Improper', 'Privilege', 'Management', 'vulnerability', 'user', 'configured', 'Shared', 'Accounts', 'Progress', 'MOVEit', 'Transfer', '(', 'SFTP', 'module', ')', 'allows', 'Privilege', 'Escalation.This', 'issue', 'affect', 'MOVEit', 'Transfer', ':', '2023.1.0', '2023.1.12', '2024.0.0', '2024.0.8', '2024.1.0', '2024.1.2'], 'cwe': 'CWE-269'}, 'CVE-2025-2631': {'basescore': 7.8, 'baseseverity': 3, 'confidentialityimpact': 3, 'integrityimpact': 3, 'vendor': 'NI', 'description': ['Out', 'bound', 'write', 'vulnerability', 'due', 'improper', 'bound', 'checking', 'NI', 'LabVIEW', 'InitCPUInformation', '(', ')', 'may', 'result', 'information', 'disclosure', 'arbitrary', 'code', 'execution', 'Successful', 'exploitation', 'requires', 'attacker', 'get', 'user', 'open', 'specially', 'crafted', 'VI', 'This', 'vulnerability', 'affect', 'NI', 'LabVIEW', '2025', 'Q1', 'prior', 'version'], 'cwe': 'CWE-787'}}\n",
    "    labels = list(data_values.keys())\n",
    "    attributes = ['basescore', 'baseseverity', 'confidentialityimpact', 'integrityimpact', 'vendor', 'description', 'cwe']\n",
    "\n",
    "\n",
    "    all_basescores = [[data_values[v][\"basescore\"]] for v in labels]\n",
    "    all_baseseverities = [[data_values[v][\"baseseverity\"]] for v in labels]\n",
    "    all_confidentialityimpacts = [[data_values[v][\"confidentialityimpact\"]] for v in labels]\n",
    "    all_integrityimpacts = [[data_values[v][\"integrityimpact\"]] for v in labels]\n",
    "    all_vendors = [[data_values[v][\"vendor\"]] for v in labels]\n",
    "    all_descriptions = [data_values[v][\"description\"] for v in labels]\n",
    "    all_cwes = [[data_values[v][\"cwe\"]] for v in labels]\n",
    "\n",
    "    all_descriptions_together = [' '.join(tokens) for tokens in all_descriptions]\n",
    "\n",
    "\n",
    "    enc_basescore = OneHotEncoder().fit_transform(all_basescores).toarray()\n",
    "    enc_baseseverities = OneHotEncoder().fit_transform(all_baseseverities).toarray()\n",
    "    enc_confidentialityimpact = OneHotEncoder().fit_transform(all_confidentialityimpacts).toarray()\n",
    "    enc_integrityimpact = OneHotEncoder().fit_transform(all_integrityimpacts).toarray()\n",
    "    enc_vendor = OneHotEncoder().fit_transform(all_vendors).toarray()\n",
    "    enc_description = CountVectorizer().fit_transform(all_descriptions_together).toarray()\n",
    "    enc_cwe = OneHotEncoder().fit_transform(all_cwes).toarray()\n",
    "    \n",
    "    \n",
    "    for i, v in enumerate(labels): #adds the encoded attributes back to the loaded json file\n",
    "        data_values[v][\"basescore\"] = enc_cwe[i]\n",
    "        data_values[v][\"baseseverity\"] = enc_cwe[i]\n",
    "        data_values[v][\"confidentialityimpact\"] = enc_cwe[i]\n",
    "        data_values[v][\"integrityimpact\"] = enc_cwe[i]\n",
    "        data_values[v][\"vendor\"] = enc_vendor[i]\n",
    "        data_values[v][\"description\"] = enc_cwe[i]\n",
    "        data_values[v][\"cwe\"] = enc_cwe[i]\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    num_label_nodes = len(labels) # Labeling of node features\n",
    "    data['label'].x = torch.eye(num_label_nodes)\n",
    "    label_ids = {val: i for i, val in enumerate(labels)}\n",
    "\n",
    "    num_attrs = len(attributes) # Attribute node features\n",
    "    data['attribute'].x = torch.randn(num_attrs, 32)\n",
    "    attr_ids = {name: i for i, name in enumerate(attributes)}\n",
    "\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    edge_attr_list = []\n",
    "    threshold = 0.8\n",
    "    description_vector_map = {}  # {desc_idx: vector}\n",
    "    desc_idx_counter = len(attributes)\n",
    "\n",
    "    for label_val in labels:\n",
    "        for attr in attributes:\n",
    "            label_idx = label_ids[label_val]\n",
    "\n",
    "            attr_idx = attr_ids[attr]\n",
    "\n",
    "            edge_index[0].append(label_idx)\n",
    "            edge_index[1].append(attr_idx)\n",
    "\n",
    "            attr_val = data_values[label_val][attr]\n",
    "            if isinstance(attr_val, (np.ndarray, list)):\n",
    "                attr_val = np.array(attr_val)\n",
    "            else:\n",
    "                attr_val = np.array([attr_val]) \n",
    "\n",
    "            edge_attr_list.append(attr_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    max_len = max(len(e) for e in edge_attr_list)\n",
    "    edge_attr_array = np.stack([np.pad(e, (0, max_len - len(e)), constant_values=0) for e in edge_attr_list])\n",
    "    edge_attr = torch.tensor(edge_attr_array, dtype=torch.float)\n",
    "\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "    data['label', 'to', 'attribute'].edge_index = edge_index\n",
    "    data['label', 'to', 'attribute'].edge_attr = edge_attr\n",
    "    data['attribute', 'rev_to', 'label'].edge_index = edge_index.flip(0)\n",
    "\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import HeteroConv, GATConv\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, out_dim, metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('label', 'to', 'attribute'): GATConv((-1, -1), hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_to', 'label'): GATConv((-1, -1), hidden_dim, add_self_loops=False)\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.lin = Linear(hidden_dim, out_dim)\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        out = self.lin(x_dict['label'])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.0195\n",
      "Epoch 10 | Loss: 0.0002\n",
      "Epoch 20 | Loss: 0.0003\n",
      "Epoch 30 | Loss: 0.0002\n",
      "Epoch 40 | Loss: 0.0000\n",
      "Epoch 50 | Loss: 0.0000\n",
      "Epoch 60 | Loss: 0.0000\n",
      "Epoch 70 | Loss: 0.0000\n",
      "Epoch 80 | Loss: 0.0001\n",
      "Epoch 90 | Loss: 0.0002\n",
      "Mean Squared Error: 0.0001\n"
     ]
    }
   ],
   "source": [
    "model = HeteroGNN(hidden_dim=32, out_dim=1, metadata=data.metadata())\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epss_scores = get_epss_scores(list(data_values.keys()), 'epss_score.csv')\n",
    "\n",
    "target = torch.tensor(epss_scores, dtype=torch.float)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out_dict = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    out = out_dict.squeeze()\n",
    "    \n",
    "    loss = F.mse_loss(out, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(data.x_dict, data.edge_index_dict).squeeze()\n",
    "    mse = F.mse_loss(predictions, target).item()\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
