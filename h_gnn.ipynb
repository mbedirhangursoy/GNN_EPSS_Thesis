{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import json\n",
    "from data_related.get_epss_score import get_epss_scores\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  label={ x=[8953, 8953] },\n",
      "  attribute={ x=[7, 32] },\n",
      "  (label, to, attribute)={\n",
      "    edge_index=[2, 62671],\n",
      "    edge_attr=[62671, 3101],\n",
      "  },\n",
      "  (attribute, rev_to, label)={ edge_index=[2, 62671] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open('data_related/h_gnn_output.json') as data_values:\n",
    "    data_values = json.load(data_values)\n",
    "\n",
    "    labels = list(data_values.keys())\n",
    "    attributes = ['basescore', 'baseseverity', 'confidentialityimpact', 'integrityimpact', 'vendor', 'description', 'cwe']\n",
    "\n",
    "\n",
    "    all_basescores = [[data_values[v][\"basescore\"]] for v in labels]\n",
    "    all_baseseverities = [[data_values[v][\"baseseverity\"]] for v in labels]\n",
    "    all_confidentialityimpacts = [[data_values[v][\"confidentialityimpact\"]] for v in labels]\n",
    "    all_integrityimpacts = [[data_values[v][\"integrityimpact\"]] for v in labels]\n",
    "    all_vendors = [[data_values[v][\"vendor\"]] for v in labels]\n",
    "    all_descriptions = [data_values[v][\"description\"] for v in labels]\n",
    "    all_cwes = [[data_values[v][\"cwe\"]] for v in labels]\n",
    "\n",
    "    all_descriptions_together = [' '.join(tokens) for tokens in all_descriptions]\n",
    "\n",
    "\n",
    "    enc_basescore = OneHotEncoder().fit_transform(all_basescores).toarray()\n",
    "    enc_baseseverities = OneHotEncoder().fit_transform(all_baseseverities).toarray()\n",
    "    enc_confidentialityimpact = OneHotEncoder().fit_transform(all_confidentialityimpacts).toarray()\n",
    "    enc_integrityimpact = OneHotEncoder().fit_transform(all_integrityimpacts).toarray()\n",
    "    enc_vendor = OneHotEncoder().fit_transform(all_vendors).toarray()\n",
    "    enc_description = CountVectorizer().fit_transform(all_descriptions_together).toarray()\n",
    "    enc_cwe = OneHotEncoder().fit_transform(all_cwes).toarray()\n",
    "    \n",
    "    \n",
    "    for i, v in enumerate(labels): #adds the encoded attributes back to the loaded json file\n",
    "        data_values[v][\"basescore\"] = enc_cwe[i]\n",
    "        data_values[v][\"baseseverity\"] = enc_cwe[i]\n",
    "        data_values[v][\"confidentialityimpact\"] = enc_cwe[i]\n",
    "        data_values[v][\"integrityimpact\"] = enc_cwe[i]\n",
    "        data_values[v][\"vendor\"] = enc_vendor[i]\n",
    "        data_values[v][\"description\"] = enc_cwe[i]\n",
    "        data_values[v][\"cwe\"] = enc_cwe[i]\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    num_label_nodes = len(labels) # Labeling of node features\n",
    "    data['label'].x = torch.eye(num_label_nodes)\n",
    "    label_ids = {val: i for i, val in enumerate(labels)}\n",
    "\n",
    "    num_attrs = len(attributes) # Attribute node features\n",
    "    data['attribute'].x = torch.randn(num_attrs, 32)\n",
    "    attr_ids = {name: i for i, name in enumerate(attributes)}\n",
    "\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    edge_attr_list = []\n",
    "    threshold = 0.8\n",
    "    description_vector_map = {}  # {desc_idx: vector}\n",
    "    desc_idx_counter = len(attributes)\n",
    "\n",
    "    for label_val in labels:\n",
    "        for attr in attributes:\n",
    "            label_idx = label_ids[label_val]\n",
    "\n",
    "            if attr == 'description':\n",
    "                current_vec = np.array(data_values[label_val][attr])\n",
    "\n",
    "                matching = False\n",
    "                for existing_idx, existing_vec in description_vector_map.items():\n",
    "                    similarity = cosine_similarity([current_vec], [existing_vec])[0][0]\n",
    "                    if similarity >= threshold:\n",
    "                        attr_idx = existing_idx\n",
    "                        matching = True\n",
    "                        break\n",
    "\n",
    "                if not matching:\n",
    "                    attr_idx = desc_idx_counter\n",
    "                    description_vector_map[attr_idx] = current_vec\n",
    "                    desc_idx_counter += 1\n",
    "\n",
    "            else:\n",
    "                attr_idx = attr_ids[attr]\n",
    "\n",
    "            edge_index[0].append(label_idx)\n",
    "            edge_index[1].append(attr_idx)\n",
    "\n",
    "            attr_val = data_values[label_val][attr]\n",
    "            if isinstance(attr_val, (np.ndarray, list)):\n",
    "                attr_val = np.array(attr_val)\n",
    "            else:\n",
    "                attr_val = np.array([attr_val]) \n",
    "\n",
    "            edge_attr_list.append(attr_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    max_len = max(len(e) for e in edge_attr_list)\n",
    "    edge_attr_array = np.stack([np.pad(e, (0, max_len - len(e)), constant_values=0) for e in edge_attr_list])\n",
    "    edge_attr = torch.tensor(edge_attr_array, dtype=torch.float)\n",
    "\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "    data['label', 'to', 'attribute'].edge_index = edge_index\n",
    "    data['label', 'to', 'attribute'].edge_attr = edge_attr\n",
    "    data['attribute', 'rev_to', 'label'].edge_index = edge_index.flip(0)\n",
    "\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import HeteroConv, GATConv\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, out_dim, metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('label', 'to', 'attribute'): GATConv((-1, -1), hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_to', 'label'): GATConv((-1, -1), hidden_dim, add_self_loops=False)\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.lin = Linear(hidden_dim, out_dim)\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        out = self.lin(x_dict['label'])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m model = HeteroGNN(hidden_dim=\u001b[32m32\u001b[39m, out_dim=\u001b[32m1\u001b[39m, metadata=data.metadata())\n\u001b[32m      4\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m0.01\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m epss_scores = \u001b[43mget_epss_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_values\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_related/epss_scores.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m target = torch.tensor(epss_scores, dtype=torch.float)\n\u001b[32m     10\u001b[39m model.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/University - VU/2024-2025/EPSS_GNN/data_related/get_epss_score.py:49\u001b[39m, in \u001b[36mget_epss_scores\u001b[39m\u001b[34m(cve_ids, file_location)\u001b[39m\n\u001b[32m     47\u001b[39m epss_scores_list = []\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cve_ids:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     epss_scores_list.append(\u001b[43mget_epss_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_location\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m epss_scores_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/University - VU/2024-2025/EPSS_GNN/data_related/get_epss_score.py:39\u001b[39m, in \u001b[36mget_epss_score\u001b[39m\u001b[34m(cve, file_location)\u001b[39m\n\u001b[32m     37\u001b[39m df = pd.read_csv(scores)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data, epss_score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[33m'\u001b[39m\u001b[33mcve\u001b[39m\u001b[33m'\u001b[39m], df[\u001b[33m'\u001b[39m\u001b[33mepss\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cve == data:\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m epss_score \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     41\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = HeteroGNN(hidden_dim=32, out_dim=1, metadata=data.metadata())\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epss_scores = get_epss_scores(list(data_values.keys()), 'data_related/epss_scores.csv')\n",
    "\n",
    "target = torch.tensor(epss_scores, dtype=torch.float)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out_dict = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    out = out_dict.squeeze()\n",
    "    \n",
    "    loss = F.mse_loss(out, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(data.x_dict, data.edge_index_dict)['label'].squeeze()\n",
    "    mse = F.mse_loss(predictions, target).item()\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
